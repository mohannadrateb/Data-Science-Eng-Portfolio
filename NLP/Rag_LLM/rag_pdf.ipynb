{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Rag system using llama index to query different pdf files\n",
    "- The data is stored in the Data directory\n",
    "- Inside the Data directory there exists 2 papers about few shot learning\n",
    "- There is a .env file in my local directory that holds the OpenAI_API_KEY\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import(   \n",
    "VectorStoreIndex, \n",
    "SimpleDirectoryReader,\n",
    "StorageContext,\n",
    "load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.response.pprint_utils import pprint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 43/43 [00:00<00:00, 200.19it/s]\n",
      "Generating embeddings: 100%|██████████| 86/86 [00:02<00:00, 38.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading the env file and variables \n",
    "def reading_indexing_files(data_dir,API_KEY_NAME):\n",
    "    #loading the env variables from the .env file\n",
    "    load_dotenv()\n",
    "    #setting up the OPENAI_API_KEY\n",
    "    os.environ[\"OPENAI_API_KEY\"]= os.getenv(API_KEY_NAME)\n",
    "    #read the different files in the Data directory and creating the meta data\n",
    "    files = SimpleDirectoryReader(data_dir).load_data()\n",
    "    #creating the indicies for those files\n",
    "    index = VectorStoreIndex.from_documents(files,show_progress= True)\n",
    "    #returning the different files and the corresponding indices for further use\n",
    "    return files, index\n",
    "files,index = reading_indexing_files(data_dir =\"Data\",API_KEY_NAME = \"API_KEY\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the query engine and its paramters:\n",
    "- The retriever paramters takes as paramters the index of the files as well as the number of top answers we want the retriever to get back\n",
    "- The postprocessor handles till what percentage of similarity does we want the retriever to bring back\n",
    "- The query engine uses the above \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_query_engine(index,similarity_top_k,similarity_cutoff):\n",
    "    retriever = VectorIndexRetriever(index = index, similarity_top_k = similarity_top_k )\n",
    "    postprocessor = SimilarityPostprocessor(similarity_cutoff = similarity_cutoff )\n",
    "    query_engine = RetrieverQueryEngine(retriever = retriever, node_postprocessors= [postprocessor])\n",
    "    return query_engine\n",
    "query_engine = setting_query_engine(index,4,0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling a query through the quesry engine\n",
    "#### Method querying_read_from_storage\n",
    "- Takes as a parmater the storage directory where the indices of the files are gonna be stored on the hard disk rather than the memory so the memory don't get exhuased if we have a lot of files\n",
    "- If the storage dir is found then we load from it else we create it and save the indices in it\n",
    "- Then use the query engine we created, with the wanted paramters and running the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Few-shot learning (FSL) is a learning method that\n",
      "involves rapidly acquiring valid information from just a few or even\n",
      "zero samples. It is inspired by human reasoning capabilities and is\n",
      "commonly applied in edge computing scenarios. FSL aims to address the\n",
      "challenge of effectively learning from small sample datasets or across\n",
      "different domains. This learning approach has shown great potential in\n",
      "various fields, especially in scenarios where traditional data-driven\n",
      "algorithms struggle due to limited data availability or domain\n",
      "variations.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: 4ad0c169-faea-4e1a-8341-a5569f6e54c8\n",
      "Similarity: 0.8668009876908989\n",
      "Text: 3 TABLE 2 A List Of Key Acronyms NOMENCLATURE Full Form\n",
      "Abbreviation Full Form Abbreviation Artiﬁcial Intelligence AI Few-Shot\n",
      "Learning FSL Deep Learning DL Machine Learning ML Zero-Shot Learning\n",
      "ZSL One-Shot Learning OSL Neural Architecture Search NAS Conventional\n",
      "Neural Network CNN K-NearestNeighbor KNN Support Vector Machine SVM\n",
      "Nearestcentro...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: 79e86b13-43f4-4cd8-b5db-a9b0090a40ed\n",
      "Similarity: 0.8632880621838525\n",
      "Text: 1 A Comprehensive Survey of Few-shot Learning: Evolution,\n",
      "Applications, Challenges, and Opportunities Yisheng Song, Ting Wang∗,\n",
      "Subrota K Mondal, Jyoti Prakash Sahoo Abstract —Few-shot learning\n",
      "(FSL) has emerged as an effective learning method and shows great\n",
      "potential. Despite the recent creative works in tackling FSL tasks,\n",
      "learning valid info...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: 3cbcd81a-bab9-4a7a-b52b-301ce51b7063\n",
      "Similarity: 0.8608013033009817\n",
      "Text: 23 IEEE conference oncomputer vision and pattern recognition,\n",
      "pages 3128–3137, 2015. [161] Peyman Bateni, Raghav Goyal, Vaden\n",
      "Masrani, Frank Wood, and Leonid Sigal. Improved few-shot visual\n",
      "classiﬁcation. In Proceedings oftheIEEE/CVF Conference onComputer\n",
      "Vision and Pattern Recognition, pages 14493–14502, 2020. [162] Dong\n",
      "Hoon Lee and Sae-Young ...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: d8221999-4c00-4d62-8210-9ca0dd5710f1\n",
      "Similarity: 0.8554983293524157\n",
      "Text: Metafun: Meta-learning with iterative functional updates. In\n",
      "International Conference onMachine Learning, pages 10617–10627. PMLR,\n",
      "2020. [184] Jialin Liu, Fei Chao, and Chih-Min Lin. Task augmentation\n",
      "by rotating for meta-learning. arXiv preprint arXiv:2003.00804, 2020.\n",
      "[185] Liang Song, Jinlu Liu, and Yongqiang Qin. Generalized adapta-\n",
      "tion for...\n"
     ]
    }
   ],
   "source": [
    "# check if storage already exists\n",
    "def querying_read_from_storage(storage_dir,index,query_engine,query):\n",
    "    storage_dir = storage_dir\n",
    "    if not os.path.exists(storage_dir):\n",
    "        index.storage_context.persist(persist_dir=storage_dir)\n",
    "    else:\n",
    "        # load the existing index\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=storage_dir)\n",
    "        index = load_index_from_storage(storage_context)\n",
    "\n",
    "    # either way we can now query the index\n",
    "    query_engine = query_engine\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "response = querying_read_from_storage(storage_dir=\"./storage\",index= index,query_engine=query_engine,query = \"Explain Few SHot Learning?\" )\n",
    "pprint_response(response,show_source= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
