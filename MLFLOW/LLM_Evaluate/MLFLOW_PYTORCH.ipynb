{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import dagshub\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Size of training dataset: 60000\n",
      "Size of test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image size: {training_data[0][0].shape}\")\n",
    "print(f\"Size of training dataset: {len(training_data)}\")\n",
    "print(f\"Size of test dataset: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),  # 10 classes in total.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"mohannadrateb/MLflow\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"mohannadrateb/MLflow\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository mohannadrateb/MLflow initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository mohannadrateb/MLflow initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dagshub.init(repo_owner='mohannadrateb',repo_name=\"MLflow\", mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/mohannadrateb/MLflow.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/21cb4ea6d81e40b697ecea5361fbee50', creation_time=1720869156240, experiment_id='1', last_update_time=1720869156240, lifecycle_stage='active', name='/mlflow-pytorch-quickstart', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/mlflow-pytorch-quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    \"\"\"Train the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            step = batch // 100 * (epoch + 1)\n",
    "            mlflow.log_metric(\"loss\", f\"{loss:2f}\", step=step)\n",
    "            mlflow.log_metric(\"accuracy\", f\"{accuracy:2f}\", step=step)\n",
    "            print(f\"loss: {loss:2f} accuracy: {accuracy:2f} [{current} / {len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    \"\"\"Evaluate the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the eval data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y)\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:2f}\", step=epoch)\n",
    "\n",
    "    print(f\"Eval metrics: \\nAccuracy: {eval_accuracy:.2f}, Avg loss: {eval_loss:2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohannadrateb/Desktop/portfolio/Port_projects/Data-Science-Eng-Portfolio/MLFLOW/LLM_Evaluate/.venv/lib/python3.9/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297716 accuracy: 0.125000 [0 / 938]\n",
      "loss: 2.218623 accuracy: 0.390625 [100 / 938]\n",
      "loss: 1.992512 accuracy: 0.437500 [200 / 938]\n",
      "loss: 1.692949 accuracy: 0.625000 [300 / 938]\n",
      "loss: 1.170610 accuracy: 0.671875 [400 / 938]\n",
      "loss: 0.989121 accuracy: 0.687500 [500 / 938]\n",
      "loss: 0.921422 accuracy: 0.703125 [600 / 938]\n",
      "loss: 0.752936 accuracy: 0.765625 [700 / 938]\n",
      "loss: 0.786248 accuracy: 0.718750 [800 / 938]\n",
      "loss: 0.811922 accuracy: 0.718750 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.74, Avg loss: 0.737757 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.688798 accuracy: 0.812500 [0 / 938]\n",
      "loss: 0.779676 accuracy: 0.687500 [100 / 938]\n",
      "loss: 0.502168 accuracy: 0.812500 [200 / 938]\n",
      "loss: 0.770441 accuracy: 0.734375 [300 / 938]\n",
      "loss: 0.707769 accuracy: 0.640625 [400 / 938]\n",
      "loss: 0.682001 accuracy: 0.781250 [500 / 938]\n",
      "loss: 0.714588 accuracy: 0.703125 [600 / 938]\n",
      "loss: 0.637330 accuracy: 0.781250 [700 / 938]\n",
      "loss: 0.683414 accuracy: 0.718750 [800 / 938]\n",
      "loss: 0.671458 accuracy: 0.734375 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.76, Avg loss: 0.647979 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.554836 accuracy: 0.812500 [0 / 938]\n",
      "loss: 0.651578 accuracy: 0.734375 [100 / 938]\n",
      "loss: 0.432528 accuracy: 0.796875 [200 / 938]\n",
      "loss: 0.692523 accuracy: 0.718750 [300 / 938]\n",
      "loss: 0.672878 accuracy: 0.671875 [400 / 938]\n",
      "loss: 0.634291 accuracy: 0.796875 [500 / 938]\n",
      "loss: 0.650684 accuracy: 0.734375 [600 / 938]\n",
      "loss: 0.627202 accuracy: 0.781250 [700 / 938]\n",
      "loss: 0.689857 accuracy: 0.718750 [800 / 938]\n",
      "loss: 0.595673 accuracy: 0.734375 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.76, Avg loss: 0.630476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\n",
    "        evaluate(test_dataloader, model, loss_fn, metric_fn, epoch=0)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohannadrateb/Desktop/portfolio/Port_projects/Data-Science-Eng-Portfolio/MLFLOW/LLM_Evaluate/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 13.73it/s]  \n"
     ]
    }
   ],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model.predict(training_data[0][0][None, :].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
